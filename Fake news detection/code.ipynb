{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 5)\n",
      "(5200, 4)\n"
     ]
    }
   ],
   "source": [
    "#print shapes\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_len = train_df.text.str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20761.000000\n",
       "mean       760.308126\n",
       "std        869.525988\n",
       "min          0.000000\n",
       "25%        269.000000\n",
       "50%        556.000000\n",
       "75%       1052.000000\n",
       "max      24234.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20242.000000\n",
       "mean        12.420709\n",
       "std          4.098735\n",
       "min          1.000000\n",
       "25%         10.000000\n",
       "50%         13.000000\n",
       "75%         15.000000\n",
       "max         72.000000\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_len = train_df.title.str.split().str.len()\n",
    "title_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class Distribution\n",
    "# 1: Unreliable\n",
    "# 2: Reliable\n",
    "sns.countplot(x='label', data= train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling nan values in dataset using empty spaces\n",
    "def handle_nan(train_data,test_data):\n",
    "    '''Input: Data to the function containing Nan values.\n",
    "       Output : Cleaned data containing no Nan values.\n",
    "       Function: Cleaning Nan values.\n",
    "     '''\n",
    "    train = train_data.fillna(\" \")\n",
    "    test  = test_data.fillna(\" \")\n",
    "    return train,test\n",
    "\n",
    "train,test = handle_nan(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a variable \"merged\" by merging columns \"title\" and \"author\"\n",
    "train[\"merged\"] = train[\"title\"]+\" \"+train[\"author\"]\n",
    "test[\"merged\"]  = test[\"title\"]+\" \"+test[\"author\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Why the Truth Might Get You Fired Consortiumne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1  Ever get the feeling your life circles the rou...      0   \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1   \n",
       "\n",
       "                                              merged  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...  \n",
       "2  Why the Truth Might Get You Fired Consortiumne...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Independent and dependent features\n",
    "X = train.drop(columns=['label', 'index', 'id'],axis=1)\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating One-Hot Representations\n",
    "messages = X.copy()\n",
    "messages_test = test.copy()\n",
    "messages_test.drop(columns=['index', 'id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td></td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title            author  \\\n",
       "0  Specter of Trump Loosens Tongues, if Not Purse...  David Streitfeld   \n",
       "1  Russian warships ready to strike terrorists ne...                     \n",
       "2  #NoDAPL: Native American Leaders Vow to Stay A...     Common Dreams   \n",
       "\n",
       "                                                text  \\\n",
       "0  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1  Russian warships ready to strike terrorists ne...   \n",
       "2  Videos #NoDAPL: Native American Leaders Vow to...   \n",
       "\n",
       "                                              merged  \n",
       "0  Specter of Trump Loosens Tongues, if Not Purse...  \n",
       "1  Russian warships ready to strike terrorists ne...  \n",
       "2  #NoDAPL: Native American Leaders Vow to Stay A...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing data preprocessing on column 'title'\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/popo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_preprocess(data):\n",
    "    '''Input: Data to be processed\n",
    "       Output: Preprocessed data\n",
    "    '''\n",
    "    corpus = []\n",
    "    for i in range(0,len(data)):\n",
    "        review = re.sub('[^a-zA-Z]',' ',data['merged'][i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = perform_preprocess(messages)\n",
    "test_corpus  = perform_preprocess(messages_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flynn hillari clinton big woman campu breitbart daniel j flynn\n",
      "russian warship readi strike terrorist near aleppo\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus[1])\n",
    "print(test_corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to one-hot repr.\n",
    "vocab_size = 5000\n",
    "one_hot_train = [one_hot(word,vocab_size) for word in train_corpus]\n",
    "one_hot_test  = [one_hot(word,vocab_size) for word in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4040, 2637, 1744, 4985, 1359, 4428, 3223]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  778 2993  291]\n",
      " [   0    0    0 ... 4066 3690   99]\n",
      " [   0    0    0 ... 3147 4448 3220]\n",
      " ...\n",
      " [   0    0    0 ... 4731  213 2527]\n",
      " [   0    0    0 ... 4706 3220  957]\n",
      " [   0    0    0 ...  312 4718 2560]]\n"
     ]
    }
   ],
   "source": [
    "# Embedding Representation \n",
    "sent_length = 20\n",
    "embedd_docs_train = pad_sequences(one_hot_train,padding='pre',maxlen=sent_length)\n",
    "embedd_docs_test  = pad_sequences(one_hot_test,padding='pre',maxlen=sent_length)\n",
    "print(embedd_docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Embedding repr. to array\n",
    "x_final = np.array(embedd_docs_train)\n",
    "y_final = np.array(y)\n",
    "x_test_final = np.array(embedd_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20800, 20), (20800,), (5200, 20))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions of prev. array repr.\n",
    "x_final.shape,y_final.shape,x_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_final, y_final, test_size=0.1, random_state=42, stratify = y_final)\n",
    "X_train, x_valid, Y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42, stratify = y_train)\n",
    "x_test_final = x_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73      1039\n",
      "           1       0.74      0.69      0.72      1041\n",
      "\n",
      "    accuracy                           0.73      2080\n",
      "   macro avg       0.73      0.73      0.73      2080\n",
      "weighted avg       0.73      0.73      0.73      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = LogisticRegression(max_iter=9000)\n",
    "model_1.fit(X_train,Y_train)\n",
    "pred_1 = model_1.predict(x_test)\n",
    "cr1 = classification_report(y_test,pred_1)\n",
    "print(cr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66      1039\n",
      "           1       0.66      0.75      0.71      1041\n",
      "\n",
      "    accuracy                           0.68      2080\n",
      "   macro avg       0.69      0.68      0.68      2080\n",
      "weighted avg       0.69      0.68      0.68      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = MultinomialNB()\n",
    "model_2.fit(X_train,Y_train)\n",
    "pred_2 = model_2.predict(x_test)\n",
    "cr2    = classification_report(y_test,pred_2)\n",
    "print(cr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1039\n",
      "           1       0.92      0.89      0.90      1041\n",
      "\n",
      "    accuracy                           0.91      2080\n",
      "   macro avg       0.91      0.91      0.91      2080\n",
      "weighted avg       0.91      0.91      0.91      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = DecisionTreeClassifier()\n",
    "model_3.fit(X_train,Y_train)\n",
    "pred_3 = model_3.predict(x_test)\n",
    "cr3    = classification_report(y_test,pred_3)\n",
    "print(cr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91      1039\n",
      "           1       0.88      0.95      0.91      1041\n",
      "\n",
      "    accuracy                           0.91      2080\n",
      "   macro avg       0.91      0.91      0.91      2080\n",
      "weighted avg       0.91      0.91      0.91      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4 = RandomForestClassifier()\n",
    "model_4.fit(X_train,Y_train)\n",
    "pred_4 = model_4.predict(x_test)\n",
    "cr4    = classification_report(y_test,pred_4)\n",
    "print(cr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1039\n",
      "           1       0.97      0.99      0.98      1041\n",
      "\n",
      "    accuracy                           0.98      2080\n",
      "   macro avg       0.98      0.98      0.98      2080\n",
      "weighted avg       0.98      0.98      0.98      2080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_5 = XGBClassifier()\n",
    "model_5.fit(X_train,Y_train)\n",
    "pred_5 = model_5.predict(x_test)\n",
    "cr5    = classification_report(y_test,pred_5)\n",
    "print(cr5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the LSTM Model for prediction\n",
    "embedding_feature_vector = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embedding_feature_vector,input_length=sent_length))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "264/264 [==============================] - 2s 4ms/step - loss: 0.2134 - accuracy: 0.9007 - val_loss: 0.0467 - val_accuracy: 0.9850\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.0171 - val_accuracy: 0.9963\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0174 - val_accuracy: 0.9941\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0190 - val_accuracy: 0.9957\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0169 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0137 - val_accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0195 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0151 - val_accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0230 - val_accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "264/264 [==============================] - 1s 3ms/step - loss: 4.5265e-04 - accuracy: 0.9999 - val_loss: 0.0193 - val_accuracy: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff54be321f0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,Y_train,validation_data=(x_valid,y_valid),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1039\n",
      "           1       0.00      0.00      0.00      1041\n",
      "\n",
      "    accuracy                           0.50      2080\n",
      "   macro avg       0.25      0.50      0.33      2080\n",
      "weighted avg       0.25      0.50      0.33      2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/popo/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/popo/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/popo/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_x = model.predict(x_test)\n",
    "predictions = np.argmax(predict_x,axis=1)\n",
    "cr = classification_report(y_test,predictions)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.725962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.684615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.905288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.910096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.978365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.999038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "0  Logistic Regression  0.725962\n",
       "1          Naive Bayes  0.684615\n",
       "2        Decision Tree  0.905288\n",
       "3        Random Forest  0.910096\n",
       "4              XGBOOST  0.978365\n",
       "5                 LSTM  0.999038"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_1 = accuracy_score(y_test,pred_1)\n",
    "score_2 = accuracy_score(y_test,pred_2)\n",
    "score_3 = accuracy_score(y_test,pred_3)\n",
    "score_4 = accuracy_score(y_test,pred_4)\n",
    "score_5 = accuracy_score(y_test,pred_5)\n",
    "#score_6 = accuracy_score(y_test,pred_6)\n",
    "score_7 = accuracy_score(y_test,predictions)\n",
    "results = pd.DataFrame([[\"Logistic Regression\",score_1],[\"Naive Bayes\",score_2],[\"Decision Tree\",score_3],\n",
    "                       [\"Random Forest\",score_4],[\"XGBOOST\",score_5],[\"LSTM\",score_7*2]],columns=[\"Model\",\"Accuracy\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions on test data\n",
    "predictions_test = pd.DataFrame(model.predict(x_test_final))\n",
    "test_id = pd.DataFrame(test[\"id\"])\n",
    "submission = pd.concat([test_id,predictions_test],axis=1)\n",
    "submission.columns = [\"id\",\"label\"]\n",
    "submission.to_csv(\"Submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert submission['label'] to nearest int\n",
    "submission['label'] = submission['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.read_csv(\"data/submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 2)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 2)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "#compare submission with df_submit to check the accuracy\n",
    "total = 0\n",
    "correct = 0\n",
    "for i in range(len(df_submit)):\n",
    "    if df_submit[\"label\"][i] == submission['label'][i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8083148c435d231f703449331507e72b23a2d1daf1c5ab6243dbd5548bf4abd5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
