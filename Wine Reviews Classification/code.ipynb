{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (129971, 14)\n"
     ]
    }
   ],
   "source": [
    "#read in the data\n",
    "path = '/media/popo/Elements/Datasets/Wine Reviews/'\n",
    "df = pd.read_csv(f'{path}wine_data.csv')\n",
    "print('Shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'country', 'description', 'designation', 'points',\n",
       "       'price', 'province', 'region_1', 'region_2', 'taster_name',\n",
       "       'taster_twitter_handle', 'title', 'variety', 'winery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(708,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['variety'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50358, 14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will take only the top 5 varieties\n",
    "top_varieties = df['variety'].value_counts().head(5).index\n",
    "df_top_5 = df[df['variety'].isin(top_varieties)]\n",
    "df_top_5.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test = df_top_5[['description', 'variety']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50358 entries, 4 to 129967\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   description  50358 non-null  object\n",
      " 1   variety      50358 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "def preprocess_text(df):\n",
    "    #remove special characters\n",
    "    df['description'] = df['description'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "    #convert to lowercase\n",
    "    df['description'] = df['description'].apply(lambda x: x.lower())\n",
    "    #remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    df['description'] = df['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "    #lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['description'] = df['description'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "    #encode the labels\n",
    "    df['variety'] = df['variety'].factorize()[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71039/3298686497.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['description'] = df['description'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
      "/tmp/ipykernel_71039/3298686497.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['description'] = df['description'].apply(lambda x: x.lower())\n",
      "/tmp/ipykernel_71039/3298686497.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['description'] = df['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
      "/tmp/ipykernel_71039/3298686497.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['description'] = df['description'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
      "/tmp/ipykernel_71039/3298686497.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['variety'] = df['variety'].factorize()[0]\n"
     ]
    }
   ],
   "source": [
    "df_train_test_processed = preprocess_text(df_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>much like regular bottling come across rather ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>soft supple plum envelope oaky structure caber...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>slightly reduced wine offer chalky tannic back...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>building year six generation winemaking tradit...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ripe aroma dark berry mingle ample note black ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description  variety\n",
       "4   much like regular bottling come across rather ...        0\n",
       "10  soft supple plum envelope oaky structure caber...        1\n",
       "12  slightly reduced wine offer chalky tannic back...        1\n",
       "14  building year six generation winemaking tradit...        2\n",
       "20  ripe aroma dark berry mingle ample note black ...        3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_test_processed['description'], df_train_test_processed['variety'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  16951\n"
     ]
    }
   ],
   "source": [
    "#check how many unique words we have\n",
    "vocab_size = len(set(' '.join(X_train).split()))\n",
    "print('Vocab size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab size\n",
    "vocab_size = 10000\n",
    "encoded_docs_train = [one_hot(d, vocab_size) for d in X_train]\n",
    "encoded_docs_test = [one_hot(d, vocab_size) for d in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_docs_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad the sequences\n",
    "max_length = 100\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=max_length, padding='post')\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10072, 100)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3754, 8464, 2567, ...,    0,    0,    0],\n",
       "       [1328, 1806, 4417, ...,    0,    0,    0],\n",
       "       [4496, 8364, 9229, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [8102, 8755, 2567, ...,    0,    0,    0],\n",
       "       [8115, 9341, 5895, ...,    0,    0,    0],\n",
       "       [ 622, 7511, 2567, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 32)           320000    \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 336,965\n",
      "Trainable params: 336,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#max length\n",
    "max_length = 100\n",
    "#embedding size\n",
    "embedding_size = 32\n",
    "#number of classes\n",
    "num_classes = 5\n",
    "#model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=max_length))\n",
    "#bidirectional LSTM\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1259/1259 [==============================] - 10s 7ms/step - loss: 0.7242 - accuracy: 0.7253\n",
      "Epoch 2/10\n",
      "1259/1259 [==============================] - 9s 7ms/step - loss: 0.4039 - accuracy: 0.8681\n",
      "Epoch 3/10\n",
      "1259/1259 [==============================] - 9s 7ms/step - loss: 0.3280 - accuracy: 0.8927\n",
      "Epoch 4/10\n",
      "1259/1259 [==============================] - 8s 7ms/step - loss: 0.2884 - accuracy: 0.9041\n",
      "Epoch 5/10\n",
      "1259/1259 [==============================] - 8s 7ms/step - loss: 0.2598 - accuracy: 0.9153\n",
      "Epoch 6/10\n",
      "1259/1259 [==============================] - 8s 6ms/step - loss: 0.2322 - accuracy: 0.9244\n",
      "Epoch 7/10\n",
      "1259/1259 [==============================] - 8s 6ms/step - loss: 0.2146 - accuracy: 0.9306\n",
      "Epoch 8/10\n",
      "1259/1259 [==============================] - 9s 7ms/step - loss: 0.1991 - accuracy: 0.9345\n",
      "Epoch 9/10\n",
      "1259/1259 [==============================] - 8s 7ms/step - loss: 0.1782 - accuracy: 0.9418\n",
      "Epoch 10/10\n",
      "1259/1259 [==============================] - 9s 7ms/step - loss: 0.1661 - accuracy: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f12c4ee17f0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(padded_docs_train, y_train, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 1s 3ms/step - loss: 0.5458 - accuracy: 0.8524\n",
      "Accuracy: 85.236299\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8083148c435d231f703449331507e72b23a2d1daf1c5ab6243dbd5548bf4abd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
